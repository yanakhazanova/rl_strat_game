# rl_strat_game

Ноутбуки с реализацией алгоритмов и финальными графиками: mini_strat_game_custom_algorithms и mini_strat_game_baseline.

---

Рассчет наград:

### Компоненты награды:
1. **Основная награда: золото**  
   ```python
   q = score[1]
   ```
   Награда начинается с количества золота, которое находится в активах игрока 2 (управляемого вашим геномом). Это базовый показатель успеха.

2. **Регуляризация**  
   ```python
   q -= np.sum(genom**2) * 0.0000000001
   ```
   Это штраф за сложность или "вес" генома. Регуляризация ограничивает чрезмерное увеличение значений генома, что способствует обобщающей способности модели. Малый коэффициент (\(10^{-10}\)) снижает влияние регуляризации, делая её второстепенным фактором.

3. **Контроль поля боя**  
   ```python
   battlefield_ours = (player1_units==0) and (player2_units>0)
   q += battlefield_ours*np.sum(field)*0.5 + (1-battlefield_ours)*np.sum(field)*0.001
   ```
   Если поле боя осталось за игроком 2 (все юниты игрока 1 уничтожены, а у игрока 2 есть выжившие), игрок 2 получает половину от общей суммы золота на поле. Если поле осталось за противником, игрок 2 получает 0.1% от несобранного золота, как утешение.

4. **Штраф за отсутствие юнитов**  
   ```python
   q += -(player2_units_with_dead==0)*1000
   ```
   Если игрок 2 не нанял ни одного юнита, он получает штраф в 1000 очков. Это мотивирует игрока активно использовать доступные ресурсы.

### Итоговая награда за игру:
```python
q_arr.append(q)
```
Для каждой пары (противник, геном) подсчитывается награда \( q \), которая затем сохраняется в массив.

---

### Усреднение наград:
После игр с разными противниками итоговая награда вычисляется как взвешенное среднее:
```python
return (np.mean(q_arr) + np.min(q_arr)) * 0.5
```
- `np.mean(q_arr)` — средняя награда, которая показывает общее качество игры.  
- `np.min(q_arr)` — минимальная награда (худший случай), которая имеет больший вес. Это помогает алгоритму уделять внимание своим слабым сторонам.

Фактор \( 0.5 \) объединяет эти два значения.

